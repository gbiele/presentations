---
title: "Learning from experimental and observational data"
author: "Guido Biele"
format: revealjs
editor: source
---

```{r}
library(dagitty)
source("dag_utils.R")
library(ggplot2)
library(patchwork)
theme_set(theme_light())
theme_update(text = element_text(size = 20))
par(mar=c(3,3,0,1), mgp=c(1,.5,0), tck=-.01)
```


# Background 

## Bias

- Most scientific enterprises attempt to estimate some quantity
- **Bias** is present if our estimate of that quantity systematically deviates from the true value. 
- When thinking about bias, it is important to clearly define the **estimand**: What is it that we are trying to estimate?
  - $bias = estimand - estimate$
  
## Estimate the right thing

A well described **estimand** is characterized by

- a clear effect measure
  - i.e., not just "Stress", but "Stress, operationalized as ... "
- a clear target population
  - for which set of humans do we want to measure an effect? 

## Internal and external validity

- if a study has internal validity, we can be sure that we have correctly estimated the effect of a manipulation in the study sample
- if a study has external validity, the effect in our study sample is the same as in the target population

<br> 

- **Studies with internal or external validity can still be biased**
- **Internal and external validity are necessary but not sufficient conditions for obtaining unbiased estimates.**


## Bias in observational studies

Nobody needs convincing that confounding is a problem

:::: {.columns}
::: {.column width="48%"}
Observed confounders are not a problem, we can simply adjust.
```{r}
fork = dagitty(
  "dag{
  C->T;
  C->O;
  }")
coord.list = 
  list(
    x=c(T=0,O=2,C=1),
    y=c(T=0,O=0,C=-1))
coordinates(fork) = coord.list
adjustedNodes(fork)  = "C"
drawmydag(fork)
```
:::

::: {.column width="4%"}
<!-- empty column to create gap -->
:::

::: {.column width="48%"}
**Un**observed confounders are a problem! There is little we can do!
```{r}
fork = dagitty(
  "dag{
  U->T;
  U->O;
  }")
coord.list = 
  list(
    x=c(T=0,O=2,U=1),
    y=c(T=0,O=0,U=-1))
latents(fork) = "U"
coordinates(fork) = coord.list
drawmydag(fork)
```
:::
::::

## Selection bias

```{r}
#| fig-align: "center"
collider = dagitty(
  "dag{
  T->S;
  L->S;
  L->O;
  }")
coord.list = 
  list(
    x=c(T=0,O=2,S=1,L=0),
    y=c(T=0,O=.5,S=.5,L=1))
coordinates(collider) = coord.list
adjustedNodes(collider)  = "S"
drawmydag(collider)
```

If the treatment determines who stays in the study and there is another variable L that causes who stays and an outcome, there will be selection bias

## Selection bias in obs. & exp. studies

:::: {.columns}
::: {.column width="48%"}
```{r}
collider = dagitty(
  "dag{
  Dist->FU;
  Edu->FU;
  Edu->Fit;
  }")
coord.list = 
  list(
    x=c(Dist=0,Fit=2,FU=1,Edu=0),
    y=c(Dist=0,Fit=.5,FU=.5,Edu=1))
coordinates(collider) = coord.list
latents(collider) = "Edu"
adjustedNodes(collider)  = "FU"
drawmydag(collider)
```
Estimating the effect of distance to work out place on fitness will be biased if participation in the follow up measurement depends on that distance and unobserved education influences both distance and fitness.
:::

::: {.column width="4%"}
<!-- empty column to create gap -->
:::

::: {.column width="48%"}
```{r}
collider = dagitty(
  "dag{
  Med->Si;
  Co->Si;
  Si->DO;
  Co->Sympt;
  }")
coord.list = 
  list(
    x=c(Med=0,Sympt=2,Si=.75,Co=0,DO=1.25),
    y=c(Med=0,Sympt=.5,Si=.5,Co=1,DO=.5))
coordinates(collider) = coord.list
latents(collider) = "Co"
adjustedNodes(collider)  = "DO"
drawmydag(collider)
```
In an RCT where medication status influences side effects, which influence drop out, and unobserved comorbid disorders influence side effects and symptoms, an unbiased causal effect cannot be estimated.
:::
::::


## Bias in experimental studies I
:::: {.columns}
::: {.column width="48%"}
```{r}
#| fig-width: 6
fork = dagitty(
  "dag{
  T->O;
  C->O;
  }")
coord.list = 
  list(
    x=c(T=0,O=1,C=0),
    y=c(T=0,O=0,C=1))
coordinates(fork) = coord.list
drawmydag(fork)
```
:::

::: {.column width="4%"}
<!-- empty column to create gap -->
:::

::: {.column width="48%"}
```{r}
#| fig-width: 6
fork = dagitty(
  "dag{
  Treat->Sympt;
  Age->Sympt;
  }")
coord.list = 
  list(
    x=c(Treat=0,Sympt=1,Age=0),
    y=c(Treat=0,Sympt=0,Age=1))
coordinates(fork) = coord.list
drawmydag(fork)
```
:::
::::

If there are some characteristics C that influence the effect of the treatment T on the outcome O (T-C-interaction), and the distribution of C is different in the study sample and target population, a randomised experiment will produce biased effect estimates. 

## "Bias" in experimental studies II




:::: {.columns}
::: {.column width="48%"}
```{r}
#| fig-width: 7
outcomes = dagitty(
  "dag{
  T->M;
  M->O_1;
  M->O_2
  }")
coord.list = 
  list(
    x=c(T=0,M=1,O_1=2,O_2=2),
    y=c(T=0,M=0,O_1=-1,O_2=1))
coordinates(outcomes) = coord.list
drawmydag(outcomes)
```
When the outcomes of interest $O_1$ and $O_2$ depend exclusively on a common mediator $M$ then results about the effect on $O_1$ will be informative about the effect on $O_2$

:::

::: {.column width="4%"}
<!-- empty column to create gap -->
:::

::: {.column width="48%"}
```{r}
#| fig-width: 7
outcomes = dagitty(
  "dag{
  T->O_1;
  T->O_2;
  X->O_2;
  }")
coord.list = 
  list(
    x=c(T=0,O_1=2,O_2=2,X=0),
    y=c(T=0,O_1=-1,O_2=1,X=1))
coordinates(outcomes) = coord.list
drawmydag(outcomes)
```
When Only one of the outcomes depends on and additional variable $X$, results from experiment with outcome $O_1$ are a biased estimate for the effect on $O_2$.

:::
::::


## Translational research needs experiments and observation

- Results from observational studies can be biased
- But so are results from experiments
- Experiments can be improved through random sampling of participants and investigation of multiple outcomes
- Even then, many experiments cannot be performed for ethical reasons

# Observational research is hard

## Does parental income influence children’s mental health?

:::: {.columns}
::: {.column width="30%"}
<small> Kinge et al.,<b> Parental income and mental disorders in children and adolescents: prospective register-based study.</b> IJE (2021). <br> "...associations between lower parental income and children’s mental disorders were partly, but not fully, attributed to other socio-demographic factors..." </small>
:::
::: {.column width="70%"}
![Results of Kinge et al. 2021 IJE](pngs/Kinge_A.png)
:::
::::


## Does parental income influence children’s mental health?

:::: {.columns}
::: {.column width="30%"}
<small> Sariaslan et al., <b> No causal associations between childhood family income and subsequent psychiatric disorders, substance misuse and violent crime arrests]: a nationwide Finnish study of >650 000 individuals and their siblings. </b> IJE (2021)  </small>
:::
::: {.column width="70%"}
![Results of Kinge et al. 2021 IJE](pngs/Sariaslan.png)
:::
::::

## Study designs

![DAGs for study designs](pngs/DAGdesigns.png)
We can analyse one data set to see in how far the results of Sariaslan and Kinge depend on modelling assumptions.

When the outcome is binary, sibling designs and panel designs with FE can only use a subset of data: Siblings and individuals with discordant outcomes, respectively.

## Samples sizes and prevalence

![](pngs/N_prev.png){width=90%,fig-align="center"}

Choosing a particular study design introduces substantial differences between the study sample and the source and target population. 

## Results: Odds & hazard ratios 

![](pngs/ORIncp1.png)

Association is stronger when parents do not already have a diagnosis.

## Results: Odds & hazard ratios 


![](pngs/ORIncp2.png)

Original results of Kinge at al (2021) and Sariaslan et al (2021) can be replicated in this data set.

## Results: Odds & hazard ratios 

![](pngs/ORIncp3.png)
Only a logistic (or cox) regression with adjustment finds an association.

## Summary of results {background-image="pngs/bias.gif"  background-opacity="0.25"}

- We can replicate the results of Kinge et al. (_there is an association_) and Sariaslan et al. (_there is no association_) using the same basic data set
- Conditional logit regression also shows no effect 

Sibling design and fixed effects panel model make fewer assumptions / have a higher internal validity. Should we rather trust these results?


## Discussion: Income variability

![](pngs/ICC.png)

Income variation in designs with high internal validity is only a fraction (~20%) of the income variability between families.
[Most income variations are very close to zero]

# Discussion: Selection bias in sib-designs

```{r}
#| fig-align: "center"
#| fig-width: 12
load("pngs/SIB_SB.Rdata")
plt
```


If parental income is a cause of # children and we are looking for a negative effect of income, sibling designs will show a biased (attenuated) association. That is, sibling design studies have higher internal validity lower external validity.

# Conclusion


- Different results of Kinge et al. (2021) and Sariaslan et al. (2021) are likely due to the choice of different analysis approaches

- Neither study can say something convincingly about causal effects (Kinge et al. acknowledge)
  - There is no categorical difference between "non-causal" and "causal" designs.
  Causal inference always needs assumptions, which should be scrutinized.

- __If__ parental income has an influence on child ADHD, the effect is likely small and also smaller than for depression or anxiety. _But the data cannot really tell us._

![](pngs/Capture.PNG)

# What can we do?
